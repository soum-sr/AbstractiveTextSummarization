{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from attention import AttentionLayer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed_reviews.csv',nrows=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set a max length to both our summary and text first we will compute the length of all the sentences and find their mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len_list, summ_len_list = [],[]\n",
    "\n",
    "for i in range(len(data['text'])):\n",
    "    text_len_list.append(len(data['text'][i].split()))\n",
    "    summ_len_list.append(len(data['summary'][i].split()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.792962162284525 4.0105488336295005\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(text_len_list), np.mean(summ_len_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we will fix the length of text to be 38 but a summary of just 4 words is too short, so we'll take around 8 words for each summary length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len = 30\n",
    "summ_len = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add unique start and end tokens to each sentences in data['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['summary'] = data['summary'].apply(lambda x: 'summstart ' + x + ' summend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that each sentence in data['summary'] will look something like this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summstart good quality dog food summend'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['summary'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(np.array(data['text']), np.array(data['summary']), \n",
    "                                                  test_size=0.1, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only consider words that are more frequent and remove any words which are very rarely occuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_words_len(tokenizer, min_occr):\n",
    "    count, total_count = 0,0\n",
    "    frequency, total_frequency = 0,0\n",
    "    \n",
    "    for key,val in tokenizer.word_counts.items():\n",
    "        total_count += 1\n",
    "        total_frequency += val\n",
    "        if val < min_occr:\n",
    "            count += 1\n",
    "            frequency += val\n",
    "    print(\"% of rare words: \", count/total_count)\n",
    "    print(\"total coverage of rare words: \", frequency/total_frequency)\n",
    "    return total_count - count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words:  0.6423736937973349\n",
      "total coverage of rare words:  0.014954988379241722\n"
     ]
    }
   ],
   "source": [
    "text_tokenizer = Tokenizer()\n",
    "text_tokenizer.fit_on_texts(list(x_train))\n",
    "x_tokenizer = Tokenizer(num_words=token_words_len(text_tokenizer,4))\n",
    "x_tokenizer.fit_on_texts(list(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words:  0.7533709067560819\n",
      "total coverage of rare words:  0.0373879678987757\n"
     ]
    }
   ],
   "source": [
    "summ_tokenizer = Tokenizer()\n",
    "summ_tokenizer.fit_on_texts(list(y_train))\n",
    "y_tokenizer = Tokenizer(num_words=token_words_len(summ_tokenizer,6))\n",
    "y_tokenizer.fit_on_texts(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text seq to int seq\n",
    "x_train_seq = x_tokenizer.texts_to_sequences(x_train)\n",
    "x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "# Padding\n",
    "x_train = pad_sequences(x_train_seq, maxlen=text_len, padding='post')\n",
    "x_val = pad_sequences(x_val_seq, maxlen=text_len, padding='post')\n",
    "\n",
    "# vocabulary\n",
    "x_voc = x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text seq to int seq\n",
    "y_train_seq = y_tokenizer.texts_to_sequences(y_train)\n",
    "y_val_seq = y_tokenizer.texts_to_sequences(y_val)\n",
    "\n",
    "# Padding\n",
    "y_train = pad_sequences(y_train_seq, maxlen=summ_len, padding='post')\n",
    "y_val = pad_sequences(y_val_seq, maxlen=summ_len, padding='post')\n",
    "\n",
    "# vocabulary\n",
    "y_voc = y_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any rows that has only stat and end tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_empty_sentence(data):\n",
    "    index = []\n",
    "    for i in range(len(data)):\n",
    "        count = 0\n",
    "        for j in data[i]:\n",
    "            if j != 0:\n",
    "                count += 1\n",
    "        if count == 2:\n",
    "            index.append(i)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = delete_empty_sentence(y_train)\n",
    "y_train = np.delete(y_train, train_index, axis=0)\n",
    "# Deleting the corresponding text to the summary\n",
    "x_train = np.delete(x_train, train_index, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = delete_empty_sentence(y_val)\n",
    "y_train = np.delete(y_train, val_index, axis=0)\n",
    "# Deleting the corresponding text to the summary\n",
    "x_train = np.delete(x_train, val_index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that done its time to build our model. Before that lets understand how the encoder decoder model works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_dim = 100\n",
    "latent_dim = 300\n",
    "# ENCODER \n",
    "\n",
    "# Input Layer\n",
    "e_input_layer = Input(shape=(text_len,))\n",
    "\n",
    "# Embedding layer\n",
    "e_embedding_layer = Embedding(x_voc, embedding_dim, trainable=True)(e_input_layer)\n",
    "\n",
    "# LSTM Layers\n",
    "e_lstm_1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "e_output_1, state_h1, state_c1 = e_lstm_1(e_embedding_layer)\n",
    "e_lstm_2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "e_output_2, state_h2, state_c2 = e_lstm_2(e_output_1)\n",
    "e_lstm_3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= e_lstm_3(e_output_2)\n",
    "\n",
    "# DECODER\n",
    "d_input_layer = Input(shape=(None,))\n",
    "\n",
    "# Embedding layer\n",
    "d_embedding_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "d_embedding = d_embedding_layer(d_input_layer)\n",
    "\n",
    "d_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "d_output,d_fwd_state, d_back_state = d_lstm(d_embedding,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, d_output])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([d_output, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "d_output = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([e_input_layer, d_input_layer], d_output)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 30, 100)      1865300     input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  [(None, 30, 300), (N 481200      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  [(None, 30, 300), (N 721200      lstm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, None, 100)    345800      input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  [(None, 30, 300), (N 721200      lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  [(None, None, 300),  481200      embedding_9[0][0]                \n",
      "                                                                 lstm_15[0][1]                    \n",
      "                                                                 lstm_15[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_15[0][0]                    \n",
      "                                                                 lstm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_16[0][0]                    \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 3458)   2078258     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,874,458\n",
      "Trainable params: 6,874,458\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78245 samples, validate on 8836 samples\n",
      "Epoch 1/20\n",
      "78245/78245 [==============================] - 693s 9ms/sample - loss: 3.3057 - val_loss: 2.9953\n",
      "Epoch 2/20\n",
      "78245/78245 [==============================] - 681s 9ms/sample - loss: 2.9653 - val_loss: 2.8252\n",
      "Epoch 3/20\n",
      "78245/78245 [==============================] - 681s 9ms/sample - loss: 2.8088 - val_loss: 2.6920\n",
      "Epoch 4/20\n",
      "78245/78245 [==============================] - 683s 9ms/sample - loss: 2.7106 - val_loss: 2.6308\n",
      "Epoch 5/20\n",
      "78245/78245 [==============================] - 681s 9ms/sample - loss: 2.6449 - val_loss: 2.5849\n",
      "Epoch 6/20\n",
      "78245/78245 [==============================] - 681s 9ms/sample - loss: 2.5973 - val_loss: 2.5566\n",
      "Epoch 7/20\n",
      "78245/78245 [==============================] - 683s 9ms/sample - loss: 2.5592 - val_loss: 2.5352\n",
      "Epoch 8/20\n",
      "78245/78245 [==============================] - 682s 9ms/sample - loss: 2.5261 - val_loss: 2.5119\n",
      "Epoch 9/20\n",
      "78245/78245 [==============================] - 682s 9ms/sample - loss: 2.4981 - val_loss: 2.4973\n",
      "Epoch 10/20\n",
      "78245/78245 [==============================] - 680s 9ms/sample - loss: 2.4747 - val_loss: 2.4799\n",
      "Epoch 11/20\n",
      "78245/78245 [==============================] - 680s 9ms/sample - loss: 2.4522 - val_loss: 2.4754\n",
      "Epoch 12/20\n",
      "78245/78245 [==============================] - 683s 9ms/sample - loss: 2.4325 - val_loss: 2.4670\n",
      "Epoch 13/20\n",
      "78245/78245 [==============================] - 680s 9ms/sample - loss: 2.4134 - val_loss: 2.4536\n",
      "Epoch 14/20\n",
      "78245/78245 [==============================] - 683s 9ms/sample - loss: 2.3953 - val_loss: 2.4434\n",
      "Epoch 15/20\n",
      "78245/78245 [==============================] - 681s 9ms/sample - loss: 2.3772 - val_loss: 2.4338\n",
      "Epoch 16/20\n",
      "78245/78245 [==============================] - 681s 9ms/sample - loss: 2.3606 - val_loss: 2.4287\n",
      "Epoch 17/20\n",
      "78245/78245 [==============================] - 681s 9ms/sample - loss: 2.3462 - val_loss: 2.4215\n",
      "Epoch 18/20\n",
      "78245/78245 [==============================] - 681s 9ms/sample - loss: 2.3323 - val_loss: 2.4240\n",
      "Epoch 19/20\n",
      "78245/78245 [==============================] - 682s 9ms/sample - loss: 2.3218 - val_loss: 2.4207\n",
      "Epoch 20/20\n",
      "78245/78245 [==============================] - 681s 9ms/sample - loss: 2.3114 - val_loss: 2.4270\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_train,y_train[:,:-1]],\n",
    "                  y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:],\n",
    "                  epochs=20,\n",
    "                  batch_size=128, \n",
    "                  validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('summarizer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('summarizer.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look into the history of the model during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time for using our model to generate summary. Before that lets create a dictionary to convert integer tokens back to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_index_word = y_tokenizer.index_word\n",
    "text_index_word = x_tokenizer.index_word\n",
    "summ_word_index = y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model\n",
    "encoder_model = Model(inputs=e_input_layer, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder model\n",
    "d_state_input_h = Input(shape=(latent_dim,))\n",
    "d_state_input_c = Input(shape=(latent_dim,))\n",
    "d_hidden_state_input = Input(shape=(text_len, latent_dim))\n",
    "\n",
    "d_embedding = d_embedding_layer(d_input_layer)\n",
    "\n",
    "d_outputs_2, state_h2, state_c2 = d_lstm(d_embedding, \n",
    "                                                    initial_state=[d_state_input_h, \n",
    "                                                                   d_state_input_c])\n",
    "# Attention layer\n",
    "a_out_inf, a_states_inf = attn_layer([d_hidden_state_input,d_outputs_2])\n",
    "d_inf_concat = Concatenate(axis=-1, name='concat')([d_outputs_2, a_out_inf])\n",
    "\n",
    "d_outputs_2 = decoder_dense(d_inf_concat)\n",
    "\n",
    "decoder_model = Model([d_input_layer] + [d_hidden_state_input,d_state_input_h, d_state_input_c],\n",
    "    [d_outputs_2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a function to generate encoded text using the encoder and then using that encoded text to generate the summary with the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(input_seq):\n",
    "    # Encoder output\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate an empty summary sequence of length 1\n",
    "    summ_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Initialize the first word with our start token\n",
    "    summ_seq[0,0] = summ_word_index['summstart']\n",
    "    \n",
    "    \n",
    "    generated_summary = ''\n",
    "    while True:\n",
    "        output_tokens, h, c = decoder_model.predict([summ_seq] + [e_out,e_h,e_c])\n",
    "        \n",
    "        # Predicted token\n",
    "        predicted_token_index = np.argmax(output_tokens[0,-1,:])\n",
    "        predicted_token = summ_index_word[predicted_token_index]\n",
    "        \n",
    "        if predicted_token != 'summend':\n",
    "            generated_summary += ' ' + predicted_token \n",
    "        \n",
    "        # break if we reached the max length or received our end token\n",
    "        if predicted_token == 'summend' or len(generated_summary.split()) >= (summ_len -1):\n",
    "            break\n",
    "            \n",
    "        # Update the summary seq\n",
    "        summ_seq = np.zeros((1,1))\n",
    "        summ_seq[0,0] = predicted_token_index\n",
    "        \n",
    "        # update internal states\n",
    "        e_h, e_c= h,c\n",
    "        \n",
    "    return generated_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define two functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=summ_word_index['summstart']) and i!=summ_word_index['summend']):\n",
    "            newString=newString+summ_index_word[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+text_index_word[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: exactly wanted yummy make sure eat chocolate dip strawberry like way around perfect \n",
      "Summary: delicious \n",
      "Predicted:  delicious\n",
      "\n",
      "Text: best honey ever bought tastes like one grandma used kid cheap worth every penny taste great plus imported \n",
      "Summary: the best honey \n",
      "Predicted:  best honey ever\n",
      "\n",
      "Text: chex snack mix cheddar flavor ounce bags new amazon selection speed service use many items \n",
      "Summary: the best \n",
      "Predicted:  great snack\n",
      "\n",
      "Text: good stuff usually drink tea without flavoring sweetener stuff strong almost bitter prefer little honey basis stuff \n",
      "Summary: potent \n",
      "Predicted:  good tea\n",
      "\n",
      "Text: runner finishing college gatorade really hit wallet hard luckily found sports amazon com may seem like lot shell gatorade first realize getting gatorade gallon shipping costs included smile begins show \n",
      "Summary: gatorade at bulk price \n",
      "Predicted:  great product\n",
      "\n",
      "Text: honey sweet without powering flavor clover honey price right get package delivered every month great since drink tea go one bottle week \n",
      "Summary: great tasting well priced \n",
      "Predicted:  best honey ever\n",
      "\n",
      "Text: great like coffee strong price fantastic compared department stores love cups \n",
      "Summary: cannot beat the price \n",
      "Predicted:  great coffee\n",
      "\n",
      "Text: packets work great quart stir popper make chore making popcorn quick easy wish contained little oil though doesnt quite get kernels \n",
      "Summary: theater popcorn \n",
      "Predicted:  great popcorn\n",
      "\n",
      "Text: seems everyone loves tootsie pops box proves success take offer quick delivery love different flavors recommend \n",
      "Summary: all time favorite tootsie pops \n",
      "Predicted:  yummy\n",
      "\n",
      "Text: different taste white grapefruit addicting like potato chips bad \n",
      "Summary: mm good \n",
      "Predicted:  great chips\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    i = np.random.randint(0,1000)\n",
    "    print(\"Text: {}\\nSummary: {}\\nPredicted: {}\\n\".format(seq2text(x_train[i]),seq2summary(y_train[i]),generate_summary(x_train[i].reshape(1,text_len))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that works really great! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
